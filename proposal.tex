\documentclass[12pt,conference,onecolumn]{IEEEtran}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{mathrsfs}
\usepackage{float}

%\usepackage[citestyle=ieee,backend=biber]{biblatex}
%\addbibresource{bibliography.bib}

% \usepackage[ruled]{algorithm2e}
% \SetKwProg{Fn}{Function}{:}{}
% \SetAlgoFuncName{Ftn.}{Function}
% \SetAlgorithmName{Alg.}{Algorithm}{List of Algorithms}

\begin{document}

\title{Proposal}
\author{
	\IEEEauthorblockN{Stephen Brett}
	\IEEEauthorblockA{The Cooper Union\\New York, NY, USA\\Email: brett@cooper.edu}
	\and
	\IEEEauthorblockN{Daniel Nakhimovich}
	\IEEEauthorblockA{The Cooper Union\\New York, NY, USA\\Email: nakhimov@cooper.edu}
	\and
	\IEEEauthorblockN{Ostap Voynarovskiy}
	\IEEEauthorblockA{The Cooper Union\\New York, NY, USA\\Email: nakhimov@cooper.edu}
}

\maketitle
\renewcommand{\baselinestretch}{1.5} 
\begin{abstract}
\textbf{\\Project dates: September 2018 -- December 2018\\}
\textnormal{
	Abstract
}
\end{abstract}
%\onecolumn \maketitle \normalsize \vfill
\IEEEpeerreviewmaketitle

\section{Project Description} \label{sec:proj_desc}

\section{Background} \label{sec:background}
\subsection{Eye Tracking}
Eye gaze tracking (EGT) systems are used to estimate the location of the point at which a person is looking. There are both intrusive and non-intrusive methods of taking the necessary measurements. Intrusive methods involve physical contact of the tracking system with the user
. One such method uses sceleral search coils, which are contact lenses that have been modified to have a coil of wire embedded in them. In a magnetic field, the position of the coil, and thus the direction in which the eye is looking, can easily and quickly be determined. This method is generally considered to be the most accurate, and is often used in medical research \cite{chennamma2013survey}. Yet since this method is invasive, requiring the insertion of a device into the body, it is not practical for commercial use. An example of intrusive tracking that is not invasive is electro-oculography, in which sensors, are adhered to the skin in the area around the eyes, and detect differences in electric potential caused by eye rotation. This is much less expensive, but is also less accurate, only to $2^{\circ}$ \cite{morimoto}.

A method of eye tracking that is conducive to everyday use involves video processing of the user's face and eyes. This can be either intrusive or non-intrusive, or even both, depending on where the cameras are mounted. For an intrusive approach, the user would wear a headset with one or more cameras attached, possibly along with light sources. With a non-intrusive method, the camera would be mounted remote from the user, giving them more freedom of motion. For this project, we are going to focus on video-based eye gaze tracking.

\subsection{Video-Based Eye Tracking}
The feature that is most commonly tracked by video-based systems is the pupil of the user's eye (assuming that both eyes point in the same direction). In order to increase the contrast between the iris and pupil, and thus more easily perform edge detection to isolate the pupil and determine its shape, additional light sources are used . These can produce IR, near-IR, or visible light. IR is much more commonly used, since light at those wavelengths is invisible to the user, and will not be distracting. Using near-IR light allows the light reflected from the eye to be detected by most commercial video cameras \cite{morimoto}. With some additional modifications to the cameras, they can be made to be more sensitive to those wavelengths of light. 

Depending of the placement of the light source with respect to the camera, different kinds of reflected light may be captured. If the IR light source is placed near the camera, the path from the source to the eye, the optical axis of the light source, will be similar to the optical axis of the camera. This has the effect of capturing the IR light that is reflected off the retina at the back of the eye, which then shines through the pupil, making the pupil appear bright. This is known as the bright pupil effect. This technique greatly increases the contrast between the iris and the pupil, making the edge detection faster and more accurate. This also allows the system to work across a range of ambient light intensities. However, the intensity of the bright pupil effect varies quite a lot between test subjects \cite{morimoto}. Thus, this method on its own is not very reliable.

If the IR light source is placed further away from the camera, the reflected light will appear as a glint in the eye, a phenomenon known as the dark pupil effect. This glint is also known as a corneal reflection (CR). The CR is then used as a reference point for calculating the gaze direction. The center of the pupil is found, and the vector between the center and the CR is found \cite{morimoto}. Some methods make use of both the bright and dark pupil effects, combining the better edge detection of the bright pupil method with the subject-independence of the dark pupil method to achieve greater accuracy. However, this requires multiple cameras and a more complex algorithm, which increases the latency of the system \cite{chennamma2013survey}. 

The determination of the gaze direction can be accomplished using either feature-based or appearance-based methods. Feature-based methods take into account the measurements of the features of the eye discussed above. The mappings of the features to the gaze direction can be based on a three-dimensional geometric model of the eye, from which the optical and visual axes of the eye are constructed, and the intersection of those vectors with the surroundings is found. These models are less sensitive to variations in lighting and viewpoint \cite{chennamma2013survey}. However, calibration is typically required to determine mapping between the measurements taken and the actual orientation of the eye. Else, there will be an approximately fixed error that will vary from user to user \cite{morimoto}. Also included in the category of feature-based methods are those that assume that assume a relationship between the features and the gaze coordinates is of a certain parametric or non-parametric form, and then use techniques such as polynomial regression or neural networks, respectively, to determine the gaze direction \cite{chennamma2013survey}.

Another class of techniques, known as appearance-based methods, do not even make use of those geometric features discussed. Instead, the system is trained with a large amount of data, in each entry of which the appearance of the user's eyes is associated with a set of gaze coordinates. The model derived from this learning is generalized to all users \cite{morimoto}.
\subsection{Future Research}

As further research is performed, it will be necessary to learn more about specific methods for detecting and tracking the head and eyes, in order to know where to look to gather the necessary data, so that computation time is not wasted on excess features. The noise, both from the user's surroundings (i.e. monitor, room lighting) and from IR light sources, must be removed from the eye image, in order to perform accurate feature detection. Algorithms for feature detection, as well as those for mapping those features to gaze coordinates, will need to be both efficient and accurate. There is a variety of system configurations, of cameras and light sources. It will be necessary to find and test multiple setups. 
\section{Proposition} \label{sec:proposition}

\bibliographystyle{IEEEtran}
\bibliography{bibliography}
%\printbibliography

\end{document}
